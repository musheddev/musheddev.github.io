(window.webpackJsonp=window.webpackJsonp||[]).push([[2],{40:function(e,t,n){"use strict";n.r(t);var r=n(12),a=n(3),o=n(41),i=n(6);function s(e){const t=Object(a.p)(e);return i.createElement(o.PrismCode,{component:"pre",className:"language-fsharp"},...t)}var l=n(15);const c=Object(l.a)(function(e){return Object(r.a)("Active Parsers",[Object(r.d)("A while ago I wrote a css parser as part of a css provider. \r\n                 Originally I wanted write a blog post about theming with css variables using the css provider but I also desire to make the date I signed up for.\r\n                 However the parsing strategies I used are interesting on their own right.\r\n                 Lets start with the parser type.\r\n                "),s("type ActiveParser<'a,'t> = IStream<'t> -> ('a * IStream<'t>) option"),Object(r.d)("Let us also look at the FParsec definition"),s("type Parser<'TResult, 'TUserState> = CharStream<'TUserState> -> Reply<'TResult>"),Object(r.d)("'a and 'TResult are equivalent being the type of desired result say an AST or a Token in the case of a tokenizer.\r\n                This result is encapsulated into two different compound types, in the FParsec case, the Reply type has Ok and Error states, whereas I used the option type.\r\n                Both IStream<'t> and CharStream<'TUserState> are stateful interfaces in which the position of the stream is particularly important in both. \r\n                The 'TUserState is a state not controlled by the CharStream but useful for a stateful parser which are parsers which require some contextual information like being in {} block or indentation level. \r\n                The CharStream's position state will be mutated by a given parser, where as in the active parser the IStream<'t> position state is built into a new IStream<'t> object in the return leaving the original unaffected.\r\n                The 't in IStream is the stream type which in our first case will be char.\r\n                "),s("type IStream<'t> =\r\n    abstract Read : int -> 't [] option //read number items off of stream if available\r\n    abstract Consume : int -> IStream<'t> //advance the head in a new stream\r\n    abstract Head : unit -> 't option //read the item at the head\r\n    abstract SubSearch : ('t -> 't -> bool) * 't [] -> int option //given a comparator and an array will find the local of that array in the stream\r\n    abstract Search : ('t -> 't -> bool) *'t -> int option //given a comparator and item will find the position of that item if possible\r\n    abstract Length : unit -> int //total length of the stream\r\n    abstract Position : unit -> int //position of head of stream"),Object(r.d)("Now this interface is functionally pure as long as the implementation of Consume does not return itself. \r\n                Further implementation details like if it was wrapping a System.IO.Stream could include more state or internal caching logic etc."),s("let PString (s : string) : ActiveParser<unit,char> =\r\n  fun stream -> \r\n    match stream.Read(s.Length) with\r\n    | Some(str) when String(str) = s -> Some((),stream.Consume(s.Length))\r\n    | _ -> None"),Object(r.d)("Our first simple parser. Let's activate it by casting it into an active pattern."),s("let (|PString|_|) = PString"),Object(r.d)("Active patterns have been used in several other libraries before for parsing, but let's look at a use case to see why."),s('let tokenise (input : IStream<char>) = //IStream<char> -> Token * IStream<char>\r\n    match input with\r\n    | PChar \']\' (_,left) -> Token.SquareEnd, left\r\n    | PString "^=" (_,left) -> Token.PrefixMatch, left\r\n    | PChar \'{\' (_,left)-> Token.CurlyStart, left\r\n    | PChar \'}\' (_,left) -> Token.CurlyEnd, left\r\n    | PString "|=" (_,left) -> Token.DashMatch, left\r\n    | PString "||" (_,left) -> Token.Column, left\r\n    | PString "~=" (_,left) -> Token.IncludeMatch, left\r\n    | Char (chr,left) -> Token.Delim chr, left'),Object(r.d)("This is only a small part of the css tokenizer but easy to follow. Notice the function signature looks like an ActiveParser.\r\n                It is missing the optional result because the css spec requires unmatched chars will marked as Delimitator tokens. \r\n                This structure becomes straight forward to unfold."),s("input |> Seq.unfold (fun stream -> if stream.Head().IsNone then None else Some(tokenise stream))"),Object(r.b)("Composability"),Object(r.d)('In this next example which checks if the char is legal for a Identifier token is built from another parser "Char". \r\n                Note that a UTF-8 char can multiple bytes and the characters that do are legal.'),s("let (|IdentCodon|_|) = function\r\n    | Char(c,left) ->\r\n        match UTF8Encoding.UTF8.GetBytes([|c|]) with\r\n        | [|u|] when u >= 65uy && u <= 90uy -> Some(c)\r\n        | [|u|] when u >= 97uy && u <= 122uy -> Some(c)\r\n        | [|u|] when u >= 48uy && u <= 57uy -> Some(c)\r\n        | [|95uy|] -> Some(c)\r\n        | [|u|] when u > 128uy -> Some(c)\r\n        | ary when ary.Length > 1 -> Some(c)\r\n        | _ -> None\r\n        |> Option.map (fun x -> x,left)\r\n    | _ -> None"),Object(r.d)("We can enhance the compossibility even more using Parser Combinators modeled from FParsec. \r\n                We will start by defining the monadic Bind, Return and Either function."),s("let Return (x: 'a): ActiveParser<'a,'t> =\r\n  fun stream -> Some(x, stream) //new parser that returns x not consuming from the stream\r\n  \r\nlet Bind (p: ActiveParser<'a,'t>) (f: 'a -> ActiveParser<'b,'t>) : ActiveParser<'b,'t> =\r\n  fun stream -> //new parser\r\n    match p stream with //that will run p\r\n    | Some(x, rest) -> (f x) rest //if successful then exec f and run the result of f\r\n    | None -> None\r\n\r\nlet Either (p1: ActiveParser<'a,'t>) (p2: ActiveParser<'a,'t>) : ActiveParser<'a,'t> =\r\n  fun stream -> //new parser\r\n    match p1 stream with //that will run p1\r\n    | None -> p2 stream //if not successful then run p2\r\n    | res -> res\r\n                "),Object(r.d)("Now for the parsec operators."),s("let (>>=) = Bind\r\n\r\nlet (>>%) p x : ActiveParser<'b,'t> =\r\n    p >>= (fun _ -> Return x) //run p; if successful return x instead\r\n\r\nlet (>>.) p1 p2 : ActiveParser<'b,'t> =\r\n    p1 >>= (fun _ -> p2) //run p1; if successful run p2 and keep its result instead\r\n\r\nlet (.>>) p1 p2 : ActiveParser<'a,'t> =\r\n    p1 >>= (fun x -> p2 >>% x) //run p1; if successful run p2 if that is successful too then keeps the p1's result\r\n\r\nlet (.>>.) p1 p2: ActiveParser<'a*'b,'t> =\r\n    p1 >>= (fun x -> p2 >>= (fun y -> Return (x, y))) //run p1; if successful run p2; if successful keep both results as tuple\r\n\r\nlet (<|>) = Either"),Object(r.d)("Now some use case examples. I included the first line to show that a parser defined as an Active Pattern can be named as a regular function type."),s("let Ident = (|Ident|_|)\r\n\r\nlet (|Function|_|) = Ident .>> PChar '(' \r\n\r\nlet (|AtKeyword|_|) = PChar '@' >>. Ident\r\n\r\nlet (|Space|_|) = NewLine <|> PChar '\\t' <|> PChar ' '"),Object(r.d)("Using the Bind and Return functions we can also build a computation expression though I generally use the other forms."),s('type ParserBuilder() =\r\n    member x.Zero () = fun stream -> Some((),stream)\r\n    member x.Bind(p, f) = Bind p f\r\n    member x.Return(y) = Return y\r\n\r\nlet parser = new ParserBuilder()\r\n\r\nlet (|Comment|_|)  =\r\n  parser {\r\n    let! chrs = PString "/*" >>. SplitWith "*/" //SplitWith is a parser that utilizes the IStream search capabilites\r\n    return String(chrs)\r\n  }'),Object(r.b)("Multi Stage Parsing"),Object(r.d)("There is still a big problem; these parsers are not contextually stateful in the way to parse nested blocks.\r\n                However we can get around that and utilize separation of concerns to make the css parser more easier to verify. \r\n                So the first step I built a Tokenizer and showed how we can unfold that to a seq of tokens, \r\n                and since IStream is generic we can build an IStream<Token>. \r\n                Next we can build a shaper which only concern is to resolve recursive block structures of css.\r\n                Lets define that structure."),s("type StylesheetShape = RuleShape list\r\n\r\nand RuleShape =\r\n    | Qualified of ComponentShape list * BlockShape\r\n    | At of string * ComponentShape list * BlockShape\r\n\r\nand ComponentShape =\r\n    | Preserved of Token\r\n    | CurlyBlock of BlockShape //{}\r\n    | ParenBlock of BlockShape //()\r\n    | SquareBlock of BlockShape //[]\r\n    | Function of string * BlockShape\r\n\r\nand BlockShape = ComponentShape list"),Object(r.d)('The next bit of code I am going to show are the recursive parsers for shaping stage. \r\n                They are the most complex of the parsers, so I will try to explain.\r\n                The active parsers by definition yield a new IStream (usally called "left") which can be further matched against which is being done here. \r\n                The Head parser which matches Head of the stream to a Token; instead of resulting with left in the second tuple position it is being matched with CompShapeList which is another active parser.\r\n                The next parser CompShapeList using a different kind of unfold function which encapsulates all the permutations for yielding a result and continuing with unfold: Break, BreakWith, Continue, ContinueWith.\r\n                Some rejiggering of the result of unfold was required to fit in an active parser. Also take note of the mutual recursion of CompShape and CompShapeList.\r\n                Cool part about this is not that it removes overall complexity of the parsing task but it isolates it from the other stages making it more analyzable/verifiable/testable.'),s('let rec (|CompShape|_|) = function\r\n    | Head (Token.Function(name), CompShapeList Token.ParenEnd (inner,left)) -> \r\n      Some(ComponentShape.Function(name,inner),left)\r\n    | Head (Token.SquareStart, CompShapeList Token.SquareEnd (inner,left)) -> \r\n      Some(ComponentShape.SquareBlock(inner),left)\r\n    | Head (Token.CurlyStart, CompShapeList Token.CurlyEnd (inner,left)) -> \r\n      Some(ComponentShape.CurlyBlock(inner),left)\r\n    | Head (Token.ParenStart, CompShapeList Token.ParenEnd (inner,left)) -> \r\n      Some(ComponentShape.ParenBlock(inner),left)\r\n    | Head (a, left) -> Some(ComponentShape.Preserved a, left)\r\n    | _ -> None\r\n\r\nand (|CompShapeList|_|) (terminal : Token) (input : IStream<Token>) =\r\n    Stream.unfold (function\r\n        | Head (a,left) when a = terminal -> Unfold.Break,left\r\n        | CompShape(shape,left) -> Unfold.ContinueWith(shape),left\r\n        | _ -> failwith "broken shaper") input\r\n    |> (function | ([],s) -> None | (x,s) -> Some(x,s))\r\n\r\nand (|RuleShape|_|) = function\r\n    | CompShapeList Token.SwiggleStart (inner,CompShapeList Token.SwiggleEnd (inner2, left)) ->\r\n        Some(RuleShape.Qualified(inner,inner2),left)\r\n    | Head (Token.At(name), CompShapeList Token.SwiggleStart (inner,CompShapeList Token.SwiggleEnd (inner2, left))) ->\r\n        Some(RuleShape.At(name,inner,inner2),left)\r\n    | _ -> None\r\n\r\nlet parseShape (input : IStream<Token>) : StylesheetShape =\r\n    Stream.unfold (function\r\n        | RuleShape(r,left) -> Unfold.ContinueWith(r),left\r\n        | Head (a, left) -> Unfold.Continue,left //do not preserve tokens not matching rules (TODO: collect comments)\r\n        | s -> Unfold.Break,s\r\n        ) input\r\n    |> fst'),Object(r.d)('The final stage of the css parser primary operates off of IStream<ComponentShape> converting from ComponentShape list. \r\n                No recursive/stateful parsers were needed. The final output type "Stylesheet" is a well structured representation of css.'),Object(r.d)("A note about performance: This active parser design was designed to be able to isolate different parts the parsing to be able to correlate them to the different spec documents. \r\n                Css tokenization and css object model were different documents. Readability and verifyabilty were of most importance. \r\n                However it is adequately fast, able parse large css files in less than a second. The streams use a shared reference to the memory so there are no Large Object Heap allocations every time the .Consume returns a new IStream."),Object(r.d)("Perhaps this post could help you the next time you need to parse some structured document."),Object(r.c)("https://github.com/Fable-Fauna/Fable.Flora","https://github.com/Fable-Fauna/Fable.Flora")])},"Active Parsers");t.default=c},41:function(e,t,n){"use strict";Object.defineProperty(t,"__esModule",{value:!0});var r=n(42);function a(e){return e&&e.__esModule?e:{default:e}}Object.defineProperty(t,"PrismCode",{enumerable:!0,get:function(){return a(r).default}}),Object.defineProperty(t,"default",{enumerable:!0,get:function(){return a(r).default}})},42:function(e,t,n){"use strict";Object.defineProperty(t,"__esModule",{value:!0});var r,a=function(){function e(e,t){for(var n=0;n<t.length;n++){var r=t[n];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(e,r.key,r)}}return function(t,n,r){return n&&e(t.prototype,n),r&&e(t,r),t}}(),o=n(6),i=(r=o)&&r.__esModule?r:{default:r},s=n(43);function l(e,t){if(!e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return!t||"object"!=typeof t&&"function"!=typeof t?e:t}var c=function(e){function t(){var e,n,r;!function(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")}(this,t);for(var a=arguments.length,o=Array(a),i=0;i<a;i++)o[i]=arguments[i];return n=r=l(this,(e=t.__proto__||Object.getPrototypeOf(t)).call.apply(e,[this].concat(o))),r._handleRefMount=function(e){r._domNode=e},l(r,n)}return function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Super expression must either be null or a function, not "+typeof t);e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,enumerable:!1,writable:!0,configurable:!0}}),t&&(Object.setPrototypeOf?Object.setPrototypeOf(e,t):e.__proto__=t)}(t,o.PureComponent),a(t,[{key:"componentDidMount",value:function(){this._hightlight()}},{key:"componentDidUpdate",value:function(){this._hightlight()}},{key:"_hightlight",value:function(){Prism.highlightElement(this._domNode,this.props.async)}},{key:"render",value:function(){var e=this.props,t=e.className,n=e.component,r=e.children;return i.default.createElement(n,{ref:this._handleRefMount,className:t},r)}}]),t}();c.propTypes={async:s.PropTypes.bool,className:s.PropTypes.string,children:s.PropTypes.any,component:s.PropTypes.node},c.defaultProps={component:"code"},t.default=c},43:function(e,t,n){e.exports=n(44)()},44:function(e,t,n){"use strict";var r=n(45);function a(){}function o(){}o.resetWarningCache=a,e.exports=function(){function e(e,t,n,a,o,i){if(i!==r){var s=new Error("Calling PropTypes validators directly is not supported by the `prop-types` package. Use PropTypes.checkPropTypes() to call them. Read more at http://fb.me/use-check-prop-types");throw s.name="Invariant Violation",s}}function t(){return e}e.isRequired=e;var n={array:e,bool:e,func:e,number:e,object:e,string:e,symbol:e,any:e,arrayOf:t,element:e,elementType:e,instanceOf:t,node:e,objectOf:t,oneOf:t,oneOfType:t,shape:t,exact:t,checkPropTypes:o,resetWarningCache:a};return n.PropTypes=n,n}},45:function(e,t,n){"use strict";e.exports="SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED"}}]);